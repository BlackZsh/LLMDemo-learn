"""
æ–‡æœ¬å¤„ç†APIå®Œæ•´Demo
æ¼”ç¤ºç¡…åŸºæµåŠ¨æ–‡æœ¬å¯¹è¯APIçš„ä½¿ç”¨
"""
import gradio as gr
from api.text_api import text_api
from config.settings import settings
from loguru import logger
import sys

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level=settings.LOG_LEVEL
)


def convert_history_to_tuples(messages):
    """
    å°†messagesæ ¼å¼è½¬æ¢ä¸ºtuplesæ ¼å¼ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰
    
    Args:
        messages: OpenAIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "..."}, ...]
        
    Returns:
        tuplesæ ¼å¼ [("user_msg", "bot_msg"), ...]
    """
    history = []
    i = 0
    while i < len(messages):
        if i + 1 < len(messages) and messages[i]["role"] == "user" and messages[i+1]["role"] == "assistant":
            history.append((messages[i]["content"], messages[i+1]["content"]))
            i += 2
        else:
            i += 1
    return history


def chat_response(message, history):
    """
    å¤„ç†èŠå¤©å“åº”ï¼ˆéæµå¼ï¼‰
    
    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ (OpenAIæ ¼å¼)
        history: å†å²å¯¹è¯è®°å½• (OpenAIæ ¼å¼)
        
    Yields:
        æ›´æ–°åçš„å†å²è®°å½•
    """
    try:
        # éªŒè¯é…ç½®
        settings.validate()
        
        # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        history.append({"role": "user", "content": message})
        yield history
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
        history.append({"role": "assistant", "content": ""})
        yield history
        
        # è½¬æ¢å†å²æ ¼å¼ç”¨äºAPIè°ƒç”¨
        chat_history = convert_history_to_tuples(history[:-2])  # ä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯
        
        # è°ƒç”¨API
        logger.info(f"ç”¨æˆ·è¾“å…¥: {message}")
        response = text_api.chat(message=message, history=chat_history)
        logger.info(f"APIå“åº”: {response[:100]}...")
        
        # æ›´æ–°åŠ©æ‰‹å›å¤
        history[-1]["content"] = response
        yield history
        
    except ValueError as e:
        error_msg = f"âš ï¸ é…ç½®é”™è¯¯: {str(e)}\n\nè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½® SILICONFLOW_API_KEY"
        logger.error(error_msg)
        history[-1]["content"] = error_msg
        yield history
    except Exception as e:
        error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history


def chat_stream_response(message, history):
    """
    å¤„ç†æµå¼èŠå¤©å“åº”
    
    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ (OpenAIæ ¼å¼)
        history: å†å²å¯¹è¯è®°å½• (OpenAIæ ¼å¼)
        
    Yields:
        æµå¼æ›´æ–°çš„å†å²è®°å½•
    """
    try:
        # éªŒè¯é…ç½®
        settings.validate()
        
        # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        history.append({"role": "user", "content": message})
        yield history
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
        history.append({"role": "assistant", "content": ""})
        yield history
        
        # è½¬æ¢å†å²æ ¼å¼ç”¨äºAPIè°ƒç”¨
        chat_history = convert_history_to_tuples(history[:-2])  # ä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯
        
        # è°ƒç”¨æµå¼API
        logger.info(f"ç”¨æˆ·è¾“å…¥(æµå¼): {message}")
        full_response = ""
        for chunk in text_api.chat_stream(message=message, history=chat_history):
            full_response += chunk
            history[-1]["content"] = full_response
            yield history
        
        logger.info(f"æµå¼APIå“åº”å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)}")
        
    except ValueError as e:
        error_msg = f"âš ï¸ é…ç½®é”™è¯¯: {str(e)}\n\nè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½® SILICONFLOW_API_KEY"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history
    except Exception as e:
        error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history


def create_demo():
    """åˆ›å»ºGradioæ¼”ç¤ºç•Œé¢"""
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
        margin: auto !important;
    }
    .header {
        text-align: center;
        padding: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    """
    
    with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:
        # æ ‡é¢˜å’Œè¯´æ˜
        gr.HTML("""
        <div class="header">
            <h1>ğŸ¤– ç¡…åŸºæµåŠ¨æ–‡æœ¬å¯¹è¯ Demo</h1>
            <p>åŸºäº OpenAI å…¼å®¹æ¥å£çš„å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ç³»ç»Ÿ</p>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("""
                ### ğŸ“‹ åŠŸèƒ½è¯´æ˜
                - âœ… æ”¯æŒå¤šè½®å¯¹è¯
                - âœ… å†å²è®°å½•ä¿å­˜
                
                ### âš™ï¸ å½“å‰é…ç½®
                """)
                
                # æ˜¾ç¤ºå½“å‰é…ç½®
                with gr.Group():
                    gr.Markdown(f"""
                    - **æ¨¡å‹**: `{settings.TEXT_MODEL}`
                    - **æœ€å¤§Token**: `{settings.MAX_TOKENS}`
                    - **æ¸©åº¦**: `{settings.TEMPERATURE}`
                    - **Top-P**: `{settings.TOP_P}`
                    """)
                
                # ç¤ºä¾‹æç¤ºè¯
                gr.Markdown("""
                ### ğŸ’¡ ç¤ºä¾‹æç¤ºè¯
                - è¯·ä»‹ç»ä¸€ä¸‹ç¡…åŸºæµåŠ¨
                - è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ 
                - å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—
                """)
        
            with gr.Column(scale=2):
                # èŠå¤©ç•Œé¢ - ä½¿ç”¨æ–°çš„messagesæ ¼å¼
                chatbot = gr.Chatbot(
                    label="å¯¹è¯çª—å£",
                    height=500,
                    type="messages",  # ä½¿ç”¨OpenAIæ ¼å¼ï¼Œé¿å…å¼ƒç”¨è­¦å‘Š
                    avatar_images=(None, "ğŸ¤–")
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        label="è¾“å…¥æ¶ˆæ¯",
                        placeholder="è¯·è¾“å…¥æ¶ˆæ¯...",
                        lines=2,
                        scale=4
                    )
                    
                with gr.Row():
                    # submit_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", scale=1)
                    stream_btn = gr.Button("ğŸ“¤ å‘é€", variant="secondary", scale=1)
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", scale=1)
        
        # åº•éƒ¨ä¿¡æ¯
        gr.Markdown("""
        ---
        ### ğŸ“– APIæ–‡æ¡£
        - [ç¡…åŸºæµåŠ¨APIæ–‡æ¡£](https://docs.siliconflow.cn/cn/api-reference/chat-completions/chat-completions)
        - æœ¬Demoä½¿ç”¨OpenAIå…¼å®¹æ¥å£æ ‡å‡†
        
        ### ğŸ”‘ é…ç½®è¯´æ˜
        1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶
        2. é…ç½® `SILICONFLOW_API_KEY=ä½ çš„APIå¯†é’¥`
        3. APIå¯†é’¥è·å–: https://cloud.siliconflow.cn/account/ak
        """)
        
        # äº‹ä»¶ç»‘å®š - æ™®é€šå‘é€ï¼ˆéæµå¼ï¼Œä½†ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼‰
        def handle_submit_wrapper(message, history):
            """å¤„ç†æ™®é€šæäº¤çš„åŒ…è£…å‡½æ•°"""
            if not message or not message.strip():
                return history, message
            
            # å…ˆæ¸…ç©ºè¾“å…¥æ¡†ï¼Œç„¶åé€æ­¥æ›´æ–°å¯¹è¯
            yield history, ""
            
            # è°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œé€æ­¥æ›´æ–°UI
            for updated_history in chat_response(message, history):
                yield updated_history, ""
        
        # submit_btn.click(
        #     fn=handle_submit_wrapper,
        #     inputs=[msg, chatbot],
        #     outputs=[chatbot, msg]
        # )
        
        # äº‹ä»¶ç»‘å®š - æµå¼å‘é€ï¼ˆæ¨èä½¿ç”¨ï¼Œä½“éªŒæ›´å¥½ï¼‰
        def handle_stream_wrapper(message, history):
            """å¤„ç†æµå¼æäº¤çš„åŒ…è£…å‡½æ•°"""
            if not message or not message.strip():
                return history, message
            
            # å…ˆæ¸…ç©ºè¾“å…¥æ¡†ï¼Œç„¶åæµå¼æ›´æ–°å¯¹è¯
            yield history, ""
            
            # æµå¼è·å–å“åº”
            for updated_history in chat_stream_response(message, history):
                yield updated_history, ""
        
        # Enteré”®æäº¤ - ä½¿ç”¨æµå¼ï¼ˆæ¨èï¼‰
        msg.submit(
            fn=handle_stream_wrapper,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
        
        # æµå¼å‘é€æŒ‰é’®
        stream_btn.click(
            fn=handle_stream_wrapper,
            inputs=[msg, chatbot],
            outputs=[chatbot, msg]
        )
        
        # æ¸…ç©ºæŒ‰é’®
        clear_btn.click(fn=lambda: ([], ""), outputs=[chatbot, msg])
    
    return demo


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("å¯åŠ¨ç¡…åŸºæµåŠ¨æ–‡æœ¬å¯¹è¯ Demo")
    logger.info("=" * 60)
    
    try:
        # éªŒè¯é…ç½®
        settings.validate()
        logger.info(f"âœ… é…ç½®éªŒè¯é€šè¿‡")
        logger.info(f"ğŸ“ ä½¿ç”¨æ¨¡å‹: {settings.TEXT_MODEL}")
        logger.info(f"ğŸ”— APIåœ°å€: {settings.SILICONFLOW_BASE_URL}")
        
    except ValueError as e:
        logger.error(f"âŒ é…ç½®é”™è¯¯: {e}")
        logger.info("ğŸ’¡ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®:")
        logger.info("   1. å¤åˆ¶ env_template.txt ä¸º .env")
        logger.info("   2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ API Key")
        logger.info("   3. API Keyè·å–åœ°å€: https://cloud.siliconflow.cn/account/ak")
        return
    
    # åˆ›å»ºå¹¶å¯åŠ¨Demo
    demo = create_demo()
    
    logger.info("ğŸš€ å¯åŠ¨ Gradio æœåŠ¡...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    )


if __name__ == "__main__":
    main()

