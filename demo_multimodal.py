"""
ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo - å®Œæ•´ç‰ˆ
é›†æˆæ–‡æœ¬å¯¹è¯ã€è¯­éŸ³åˆæˆã€å›¾åƒè¯†åˆ«åŠŸèƒ½
"""
import gradio as gr
import os
import time
from pathlib import Path
from loguru import logger
import sys

# å¯¼å…¥APIæ¨¡å—
from api.text_api import text_api
from api.tts_api import tts_api
from api.vision_api import vision_api
from api.asr_api import asr_api
from config.settings import settings

# ==================== é…ç½®æ—¥å¿— ====================
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level=settings.LOG_LEVEL
)


# ==================== å·¥å…·å‡½æ•° ====================

def ensure_output_dirs():
    """
    ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    åˆ›å»ºéŸ³é¢‘å’Œå›¾ç‰‡çš„ä¿å­˜ç›®å½•
    """
    Path(settings.AUDIO_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    Path(settings.IMAGE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)


def convert_history_to_tuples(messages):
    """
    å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„æ ¼å¼
    
    Args:
        messages: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
        
    Returns:
        [("user_msg", "assistant_msg"), ...]
    
    è¯´æ˜:
        è¿™ä¸ªè½¬æ¢æ˜¯ä¸ºäº†å…¼å®¹text_apiçš„å†å²è®°å½•æ ¼å¼
    """
    history = []
    i = 0
    while i < len(messages):
        # æ¯æ¬¡å¤„ç†ä¸€å¯¹user-assistantæ¶ˆæ¯
        if i + 1 < len(messages) and messages[i]["role"] == "user" and messages[i+1]["role"] == "assistant":
            history.append((messages[i]["content"], messages[i+1]["content"]))
            i += 2
        else:
            i += 1
    return history


# ==================== æ–‡æœ¬å¯¹è¯åŠŸèƒ½ ====================

def chat_stream_response(message, history):
    """
    å¤„ç†æµå¼èŠå¤©å“åº”ï¼ˆçº¯æ–‡æœ¬å¯¹è¯ï¼Œå‚è€ƒ demo_text.py çš„æ¸…æ™°é€»è¾‘ï¼‰
    
    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        history: å†å²å¯¹è¯è®°å½•ï¼ˆOpenAIæ ¼å¼ï¼‰
        
    Yields:
        æ›´æ–°çš„å†å²è®°å½•
        
    åŠŸèƒ½æµç¨‹:
        1. ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å² â†’ ç”¨æˆ·ç«‹å³çœ‹åˆ°è‡ªå·±çš„è¾“å…¥
        2. æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯ â†’ å‡†å¤‡æ¥æ”¶æµå¼è¾“å‡º
        3. æµå¼è·å–AIå›å¤ â†’ é€å­—æ˜¾ç¤ºï¼Œä½“éªŒæµç•…
    """
    try:
        # éªŒè¯é…ç½®
        settings.validate()
        
        # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        history.append({"role": "user", "content": message})
        yield history
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
        history.append({"role": "assistant", "content": ""})
        yield history
        
        # è½¬æ¢å†å²æ ¼å¼ç”¨äºAPIè°ƒç”¨
        chat_history = convert_history_to_tuples(history[:-2])  # ä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯
        
        # è°ƒç”¨æµå¼API
        logger.info(f"ç”¨æˆ·è¾“å…¥(æµå¼): {message}")
        full_response = ""
        for chunk in text_api.chat_stream(message=message, history=chat_history):
            full_response += chunk
            history[-1]["content"] = full_response
            yield history
        
        logger.info(f"æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)}")
        
    except ValueError as e:
        error_msg = f"âš ï¸ é…ç½®é”™è¯¯: {str(e)}\n\nè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½® SILICONFLOW_API_KEY"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history
    except Exception as e:
        error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history


def synthesize_speech(text):
    """
    è¯­éŸ³åˆæˆåŠŸèƒ½ï¼ˆç‹¬ç«‹å‡½æ•°ï¼Œä½œä¸ºå¯é€‰çš„åå¤„ç†æ­¥éª¤ï¼‰
    
    Args:
        text: è¦åˆæˆè¯­éŸ³çš„æ–‡æœ¬
        
    Returns:
        str: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
    """
    try:
        if not text or not text.strip():
            return None
            
        logger.info("å¼€å§‹è¯­éŸ³åˆæˆ...")
        
        # ç”Ÿæˆå”¯ä¸€çš„éŸ³é¢‘æ–‡ä»¶å
        timestamp = int(time.time())
        audio_filename = f"tts_{timestamp}.wav"
        audio_path = os.path.join(settings.AUDIO_OUTPUT_DIR, audio_filename)
        
        # è°ƒç”¨TTS API
        tts_api.synthesize(text=text, save_path=audio_path)
        
        logger.info(f"âœ… è¯­éŸ³åˆæˆæˆåŠŸ: {audio_path}")
        return audio_path
        
    except Exception as e:
        logger.warning(f"âš ï¸ è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
        return None


# ==================== å›¾åƒè¯†åˆ«åŠŸèƒ½ ====================

def analyze_image(image, question):
    """
    åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆæ”¯æŒä¸¤ç§å›¾ç‰‡è¾“å…¥æ–¹å¼ï¼‰
    
    æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.siliconflow.cn/cn/userguide/capabilities/multimodal-vision
    ç¡…åŸºæµåŠ¨æ”¯æŒï¼š
    1. ç½‘ç»œå›¾ç‰‡URL - ç›´æ¥ä½¿ç”¨
    2. æœ¬åœ°å›¾ç‰‡ - è‡ªåŠ¨è½¬æ¢ä¸ºBase64ç¼–ç 
    
    Args:
        image: å›¾ç‰‡æ–‡ä»¶ï¼ˆæ¥è‡ªæ‘„åƒå¤´æˆ–ä¸Šä¼ ï¼‰
                - None: æ²¡æœ‰å›¾ç‰‡
                - str: å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨Base64ç¼–ç ï¼‰
                - numpy.ndarray: å›¾ç‰‡æ•°ç»„ï¼ˆæ‘„åƒå¤´æ‹æ‘„ï¼Œä¼šè‡ªåŠ¨ä¿å­˜å¹¶ç¼–ç ï¼‰
        question: ç”¨æˆ·å¯¹å›¾ç‰‡çš„æé—®
                 - å¦‚æœä¸ºç©ºï¼Œé»˜è®¤æè¿°å›¾ç‰‡å†…å®¹
                 - å¦‚æœæœ‰å†…å®¹ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜
        
    Returns:
        str: å›¾ç‰‡åˆ†æç»“æœ
        
    æŠ€æœ¯å®ç°:
        1. Gradioæ‘„åƒå¤´ â†’ numpyæ•°ç»„ â†’ ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        2. Gradioä¸Šä¼  â†’ æ–‡ä»¶è·¯å¾„ â†’ ç›´æ¥ä½¿ç”¨
        3. vision_api è‡ªåŠ¨åˆ¤æ–­æ˜¯URLè¿˜æ˜¯æœ¬åœ°è·¯å¾„
        4. æœ¬åœ°è·¯å¾„ä¼šè‡ªåŠ¨è½¬æ¢ä¸º data:image/jpeg;base64,... æ ¼å¼
        5. æ— éœ€æ‰‹åŠ¨ä¸Šä¼ åˆ°ç½‘ç»œï¼Œç›´æ¥é€šè¿‡Base64ä¼ è¾“
    """
    try:
        # ===== æ­¥éª¤1: æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ =====
        if image is None:
            return "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨æ‘„åƒå¤´æ‹ç…§"
        
        # ===== æ­¥éª¤2: å¤„ç†ä¸åŒç±»å‹çš„å›¾ç‰‡è¾“å…¥ =====
        import numpy as np
        from PIL import Image
        
        if isinstance(image, np.ndarray):
            # æ‘„åƒå¤´æ‹ç…§ï¼šnumpyæ•°ç»„ â†’ ä¸´æ—¶æ–‡ä»¶ â†’ Base64ç¼–ç 
            logger.info("å¤„ç†æ‘„åƒå¤´å›¾ç‰‡ï¼ˆå°†è‡ªåŠ¨Base64ç¼–ç ï¼‰")
            
            # è½¬æ¢ä¸ºPIL Image
            pil_image = Image.fromarray(image)
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            timestamp = int(time.time())
            temp_image_path = os.path.join(settings.IMAGE_OUTPUT_DIR, f"camera_{timestamp}.jpg")
            pil_image.save(temp_image_path)
            
            image_source = temp_image_path
            logger.info(f"æ‘„åƒå¤´å›¾ç‰‡å·²ä¿å­˜: {temp_image_path}")
            
        else:
            # ä¸Šä¼ æ–‡ä»¶ï¼šç›´æ¥ä½¿ç”¨è·¯å¾„ï¼ˆvision_apiä¼šè‡ªåŠ¨Base64ç¼–ç ï¼‰
            image_source = image
            logger.info(f"å¤„ç†ä¸Šä¼ å›¾ç‰‡: {image_source}ï¼ˆå°†è‡ªåŠ¨Base64ç¼–ç ï¼‰")
        
        # ===== æ­¥éª¤3: æ„å»ºæç¤ºè¯ =====
        if question and question.strip():
            # ç”¨æˆ·æœ‰å…·ä½“é—®é¢˜
            prompt = question
            logger.info(f"ç”¨æˆ·é—®é¢˜: {question}")
        else:
            # é»˜è®¤æè¿°å›¾ç‰‡
            prompt = None  # vision_apiä¼šä½¿ç”¨é»˜è®¤æç¤ºè¯
            logger.info("ä½¿ç”¨é»˜è®¤æè¿°æ¨¡å¼")
        
        # ===== æ­¥éª¤4: è°ƒç”¨Vision API =====
        logger.info("å¼€å§‹åˆ†æå›¾ç‰‡...")
        description = vision_api.describe_image(
            image_source=image_source,
            prompt=prompt,
            detail="auto"  # è‡ªåŠ¨é€‰æ‹©åˆ†æè¯¦ç»†ç¨‹åº¦
        )
        
        logger.info(f"å›¾ç‰‡åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(description)}")
        
        # æ£€æŸ¥æ˜¯å¦è¿”å›äº†403é”™è¯¯æ¶ˆæ¯
        if "403" in description or "Forbidden" in description:
            return f"""âŒ å›¾åƒè¯†åˆ«æƒé™é”™è¯¯ (403 Forbidden)

å½“å‰æ¨¡å‹ï¼š{settings.VLM_MODEL}

ğŸ”§ å¿«é€Ÿä¿®å¤æ–¹æ³•ï¼š

1. æ‰“å¼€é¡¹ç›®ç›®å½•ä¸­çš„ .env æ–‡ä»¶
2. ä¿®æ”¹ VLM_MODEL é…ç½®ï¼Œå°è¯•ä»¥ä¸‹æ¨¡å‹ï¼š

   VLM_MODEL=Qwen/Qwen2-VL-7B-Instruct

3. ä¿å­˜åé‡å¯åº”ç”¨

ğŸ’¡ æ›´å¤šè§£å†³æ–¹æ¡ˆï¼š
   - è¿è¡Œè¯Šæ–­è„šæœ¬ï¼špython test_vision_api.py
   - æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£ï¼šVISION_FIX.md
   - æ£€æŸ¥ API æƒé™ï¼šhttps://cloud.siliconflow.cn/account/ak

åŸå§‹é”™è¯¯ï¼š{description}"""
        
        return description
        
    except Exception as e:
        error_msg = f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        
        # ç‰¹æ®Šå¤„ç†403é”™è¯¯
        if "403" in str(e) or "Forbidden" in str(e):
            return f"""âŒ å›¾åƒè¯†åˆ«æƒé™é”™è¯¯ (403 Forbidden)

å½“å‰æ¨¡å‹ï¼š{settings.VLM_MODEL}

ğŸ”§ å¿«é€Ÿä¿®å¤æ–¹æ³•ï¼š

1. æ‰“å¼€ .env æ–‡ä»¶
2. ä¿®æ”¹ VLM_MODEL ä¸ºï¼šQwen/Qwen2-VL-7B-Instruct
3. ä¿å­˜å¹¶é‡å¯åº”ç”¨

ğŸ’¡ æˆ–è¿è¡Œè¯Šæ–­è„šæœ¬ï¼špython test_vision_api.py

åŸå§‹é”™è¯¯ï¼š{str(e)}"""
        
        return error_msg


# ==================== è¯­éŸ³è¯†åˆ«åŠŸèƒ½ ====================

def transcribe_audio(audio_file, language_choice):
    """
    è¯­éŸ³è¯†åˆ«ï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ¥è‡ªéº¦å…‹é£å½•éŸ³æˆ–ä¸Šä¼ ï¼‰
                   - None: æ²¡æœ‰éŸ³é¢‘
                   - str: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        language_choice: è¯­è¨€é€‰æ‹©
                        - "auto": è‡ªåŠ¨æ£€æµ‹
                        - "zh": ä¸­æ–‡
                        - "en": è‹±æ–‡
                        - "ja": æ—¥è¯­
                        - "yue": ç²¤è¯­
    
    Returns:
        str: è¯†åˆ«å‡ºçš„æ–‡å­—å†…å®¹
    """
    try:
        # ===== æ­¥éª¤1: æ£€æŸ¥éŸ³é¢‘æ˜¯å¦å­˜åœ¨ =====
        if audio_file is None:
            return "âš ï¸ è¯·å…ˆå½•åˆ¶æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
        
        logger.info(f"å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_file}")
        logger.info(f"è¯­è¨€è®¾ç½®: {language_choice}")
        
        # ===== æ­¥éª¤2: è°ƒç”¨ASR API =====
        logger.info("å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        
        # å°†è¯­è¨€é€‰æ‹©æ˜ å°„åˆ°APIå‚æ•°
        language_map = {
            "è‡ªåŠ¨æ£€æµ‹": "auto",
            "ä¸­æ–‡": "zh",
            "è‹±æ–‡": "en",
            "æ—¥è¯­": "ja",
            "ç²¤è¯­": "yue"
        }
        language = language_map.get(language_choice, "auto")
        
        text = asr_api.transcribe(
            audio_source=audio_file,
            language=language,
            response_format="text"
        )
        
        logger.info(f"è¯­éŸ³è¯†åˆ«å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        
        # è¿”å›æ ¼å¼åŒ–çš„ç»“æœ
        return f"""âœ… è¯†åˆ«æˆåŠŸï¼

ğŸ“ è¯†åˆ«æ–‡æœ¬ï¼š

{text}

---
ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š
- æ–‡æœ¬é•¿åº¦ï¼š{len(text)} å­—ç¬¦
- è¯­è¨€è®¾ç½®ï¼š{language_choice}
- æ¨¡å‹ï¼š{settings.SPEECH_MODEL}"""
        
    except Exception as e:
        error_msg = f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        
        # ç‰¹æ®Šå¤„ç†å¸¸è§é”™è¯¯
        if "403" in str(e) or "Forbidden" in str(e):
            return f"""âŒ è¯­éŸ³è¯†åˆ«æƒé™é”™è¯¯ (403 Forbidden)

å½“å‰æ¨¡å‹ï¼š{settings.SPEECH_MODEL}

ğŸ”§ å¯èƒ½çš„åŸå› ï¼š
1. API Key æ²¡æœ‰è®¿é—®è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„æƒé™
2. è´¦æˆ·ä½™é¢ä¸è¶³

ğŸ’¡ è§£å†³æ–¹æ³•ï¼š
1. æ£€æŸ¥ API æƒé™ï¼šhttps://cloud.siliconflow.cn/account/ak
2. æŸ¥çœ‹è´¦æˆ·ä½™é¢ï¼šhttps://cloud.siliconflow.cn/account/billing
3. å°è¯•è¿è¡Œæµ‹è¯•è„šæœ¬ï¼špython test/test_asr_local.py

åŸå§‹é”™è¯¯ï¼š{str(e)}"""
        
        elif "400" in str(e) or "Bad Request" in str(e):
            return f"""âŒ éŸ³é¢‘æ ¼å¼é”™è¯¯ (400 Bad Request)

å¯èƒ½çš„åŸå› ï¼š
1. éŸ³é¢‘æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ
2. éŸ³é¢‘æ–‡ä»¶æŸå
3. æ–‡ä»¶å¤§å°è¶…å‡ºé™åˆ¶

ğŸ’¡ è§£å†³æ–¹æ³•ï¼š
1. æ”¯æŒçš„æ ¼å¼ï¼šMP3, WAV, M4A, FLAC, OGG, WebM
2. å»ºè®®æ–‡ä»¶å¤§å°ï¼š< 25MB
3. å»ºè®®éŸ³é¢‘æ—¶é•¿ï¼š< 30åˆ†é’Ÿ
4. å¦‚æœæ˜¯å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦æ­£å¸¸

åŸå§‹é”™è¯¯ï¼š{str(e)}"""
        
        return error_msg


# ==================== Gradioç•Œé¢ ====================

def create_demo():
    """
    åˆ›å»ºGradioå¤šæ¨¡æ€æ¼”ç¤ºç•Œé¢
    
    ç•Œé¢ç»“æ„:
        - Tab 1: æ–‡æœ¬å¯¹è¯ï¼ˆæ”¯æŒè¯­éŸ³æ’­æŠ¥ï¼‰
        - Tab 2: å›¾åƒè¯†åˆ«ï¼ˆæ”¯æŒæ‘„åƒå¤´å’Œä¸Šä¼ ï¼‰
    """
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1400px !important;
        margin: auto !important;
    }
    .header {
        text-align: center;
        padding: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .info-box {
        background-color: #f0f7ff;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 10px 0;
    }
    """
    
    with gr.Blocks(css=custom_css, theme=gr.themes.Soft(), title="ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo") as demo:
        
        # ==================== é¡µé¢æ ‡é¢˜ ====================
        gr.HTML("""
        <div class="header">
            <h1>ğŸ¤– å¤šæ¨¡æ€AIåŠ©æ‰‹ Demo</h1>
            <p>æ–‡æœ¬å¯¹è¯ Â· è¯­éŸ³åˆæˆ Â· å›¾åƒè¯†åˆ« - ä¸€ç«™å¼AIä½“éªŒ</p>
        </div>
        """)
        
        # ==================== Tab 1: æ–‡æœ¬å¯¹è¯ ====================
        with gr.Tab("ğŸ’¬ æ™ºèƒ½å¯¹è¯"):
            with gr.Row():
                # å·¦ä¾§ï¼šé…ç½®å’Œè¯´æ˜
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ“‹ åŠŸèƒ½è¯´æ˜
                    - âœ… å¤šè½®å¯¹è¯è®°å¿†
                    - âœ… æµå¼å®æ—¶è¾“å‡º
                    - ğŸ”Š è¯­éŸ³æ’­æŠ¥ï¼ˆå¯é€‰ï¼‰
                    
                    ### âš™ï¸ å½“å‰é…ç½®
                    """)
                    
                    with gr.Group():
                        gr.Markdown(f"""
                        - **æ–‡æœ¬æ¨¡å‹**: `{settings.TEXT_MODEL}`
                        - **è¯­éŸ³æ¨¡å‹**: `{settings.TTS_MODEL}`
                        - **æœ€å¤§Token**: `{settings.MAX_TOKENS}`
                        - **æ¸©åº¦**: `{settings.TEMPERATURE}`
                        """)
                    
                    gr.Markdown("""
                    ### ğŸ’¡ ç¤ºä¾‹é—®é¢˜
                    - è¯·ä»‹ç»ä¸€ä¸‹ç¡…åŸºæµåŠ¨
                    - å†™ä¸€ä¸ªPythonå¿«é€Ÿæ’åº
                    - è§£é‡Šä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹
                    - å¸®æˆ‘å†™é¦–å…³äºAIçš„è¯—
                    """)
                
                # å³ä¾§ï¼šå¯¹è¯ç•Œé¢
                with gr.Column(scale=2):
                    # èŠå¤©çª—å£ï¼ˆä½¿ç”¨messagesæ ¼å¼ï¼‰
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯çª—å£",
                        height=450,
                        type="messages",  # OpenAIæ ¼å¼
                        avatar_images=(None, "ğŸ¤–")
                    )
                    
                    # éŸ³é¢‘æ’­æ”¾å™¨
                    audio_output = gr.Audio(
                        label="è¯­éŸ³æ’­æŠ¥",
                        type="filepath",
                        autoplay=True,  # è‡ªåŠ¨æ’­æ”¾
                        visible=True
                    )
                    
                    # è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        msg = gr.Textbox(
                            label="è¾“å…¥æ¶ˆæ¯",
                            placeholder="è¯·è¾“å…¥æ¶ˆæ¯...",
                            lines=2,
                            scale=4
                        )
                    
                    # æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        enable_tts = gr.Checkbox(
                            label="ğŸ”Š è¯­éŸ³æ’­æŠ¥",
                            value=False,
                            info="å‹¾é€‰åå°†å›å¤è½¬ä¸ºè¯­éŸ³"
                        )
                        send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", scale=1)
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", scale=1)
            
            # ===== äº‹ä»¶ç»‘å®š =====
            
            # åŒ…è£…å‡½æ•°ï¼šå¤„ç†æµå¼å“åº”ï¼ˆå‚è€ƒ demo_text.py çš„æ¸…æ™°ç»“æ„ï¼‰
            def handle_stream_wrapper(message, history, enable_tts):
                """
                å¤„ç†æµå¼æäº¤çš„åŒ…è£…å‡½æ•°
                
                åŠŸèƒ½:
                    1. æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
                    2. æ¸…ç©ºè¾“å…¥æ¡†
                    3. æµå¼æ›´æ–°å¯¹è¯
                    4. ï¼ˆå¯é€‰ï¼‰ç”Ÿæˆè¯­éŸ³
                """
                if not message or not message.strip():
                    return history, "", None
                
                # å…ˆæ¸…ç©ºè¾“å…¥æ¡†
                yield history, "", None
                
                # æµå¼è·å–æ–‡æœ¬å“åº”
                final_history = None
                for updated_history in chat_stream_response(message, history):
                    final_history = updated_history
                    yield updated_history, "", None
                
                # å¦‚æœå¯ç”¨TTSï¼Œåœ¨æ–‡æœ¬å“åº”å®Œæˆåç”Ÿæˆè¯­éŸ³
                audio_path = None
                if enable_tts and final_history and final_history[-1]["role"] == "assistant":
                    response_text = final_history[-1]["content"]
                    audio_path = synthesize_speech(response_text)
                
                # æœ€ç»ˆè¾“å‡ºï¼ˆå¸¦æˆ–ä¸å¸¦éŸ³é¢‘ï¼‰
                yield final_history, "", audio_path
            
            # Enteré”®æäº¤
            msg.submit(
                fn=handle_stream_wrapper,
                inputs=[msg, chatbot, enable_tts],
                outputs=[chatbot, msg, audio_output]
            )
            
            # å‘é€æŒ‰é’®
            send_btn.click(
                fn=handle_stream_wrapper,
                inputs=[msg, chatbot, enable_tts],
                outputs=[chatbot, msg, audio_output]
            )
            
            # æ¸…ç©ºæŒ‰é’®
            clear_btn.click(
                fn=lambda: ([], "", None),
                outputs=[chatbot, msg, audio_output]
            )
        
        # ==================== Tab 2: å›¾åƒè¯†åˆ« ====================
        with gr.Tab("ğŸ–¼ï¸ å›¾åƒè¯†åˆ«"):
            with gr.Row():
                # å·¦ä¾§ï¼šå›¾ç‰‡è¾“å…¥
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ“¸ å›¾ç‰‡æ¥æº
                    æ”¯æŒä¸¤ç§æ–¹å¼è¾“å…¥å›¾ç‰‡:
                    """)
                    
                    with gr.Tabs():
                        # æ‘„åƒå¤´æ‹ç…§
                        with gr.Tab("ğŸ“· æ‘„åƒå¤´"):
                            camera_input = gr.Image(
                                label="æ‘„åƒå¤´",
                                sources=["webcam"],  # åªå…è®¸æ‘„åƒå¤´
                                type="numpy"
                            )
                        
                        # ä¸Šä¼ å›¾ç‰‡
                        with gr.Tab("ğŸ“ ä¸Šä¼ "):
                            upload_input = gr.Image(
                                label="ä¸Šä¼ å›¾ç‰‡",
                                sources=["upload"],  # åªå…è®¸ä¸Šä¼ 
                                type="filepath"
                            )
                    
                    gr.Markdown("""
                    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
                    1. **æ‘„åƒå¤´æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ“·æ‘„åƒå¤´"æ ‡ç­¾
                       - ç‚¹å‡»ç›¸æœºå›¾æ ‡æ‹ç…§
                       - ç…§ç‰‡ä¼šè‡ªåŠ¨åˆ†æ
                    
                    2. **ä¸Šä¼ æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ“ä¸Šä¼ "æ ‡ç­¾
                       - æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼ å›¾ç‰‡
                       - æ”¯æŒ JPG, PNG, WebP ç­‰æ ¼å¼
                    
                    3. **æé—®æ¨¡å¼**:
                       - åœ¨å³ä¾§è¾“å…¥å…·ä½“é—®é¢˜
                       - ç•™ç©ºåˆ™è‡ªåŠ¨æè¿°å›¾ç‰‡å†…å®¹
                    
                    ### âš™ï¸ å½“å‰æ¨¡å‹
                    """)
                    
                    gr.Markdown(f"`{settings.VLM_MODEL}`")
                
                # å³ä¾§ï¼šè¯†åˆ«ç»“æœ
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¯ è¯†åˆ«ç»“æœ")
                    
                    # é—®é¢˜è¾“å…¥æ¡†
                    question_input = gr.Textbox(
                        label="å‘AIæé—®ï¼ˆå¯é€‰ï¼‰",
                        placeholder="ä¾‹å¦‚: å›¾ç‰‡ä¸­æœ‰å‡ ä¸ªäºº? è¿™æ˜¯ä»€ä¹ˆåœ°æ–¹? å›¾ç‰‡çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆ?",
                        lines=2
                    )
                    
                    # åˆ†ææŒ‰é’®
                    analyze_btn = gr.Button("ğŸ” åˆ†æå›¾ç‰‡", variant="primary", size="lg")
                    
                    # ç»“æœæ˜¾ç¤º
                    result_output = gr.Textbox(
                        label="åˆ†æç»“æœ",
                        lines=15,
                        placeholder="åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                        show_copy_button=True  # æ˜¾ç¤ºå¤åˆ¶æŒ‰é’®
                    )
                    
                    # ç¤ºä¾‹é—®é¢˜
                    with gr.Accordion("ğŸ“– ç¤ºä¾‹é—®é¢˜", open=False):
                        gr.Markdown("""
                        **æè¿°ç±»**:
                        - è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡
                        - å›¾ç‰‡çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ
                        - è¿™å¼ å›¾ç‰‡ç»™ä½ ä»€ä¹ˆæ„Ÿè§‰ï¼Ÿ
                        
                        **è¯†åˆ«ç±»**:
                        - å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆç‰©ä½“ï¼Ÿ
                        - èƒ½è®¤å‡ºè¿™æ˜¯ä»€ä¹ˆåœ°æ–¹å—ï¼Ÿ
                        - å›¾ç‰‡ä¸­æœ‰å‡ ä¸ªäººï¼Ÿ
                        
                        **åˆ†æç±»**:
                        - å›¾ç‰‡çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
                        - è¿™å¼ å›¾ç‰‡å¯èƒ½åœ¨è¡¨è¾¾ä»€ä¹ˆï¼Ÿ
                        - å›¾ç‰‡çš„è‰²è°ƒå’Œæ°›å›´å¦‚ä½•ï¼Ÿ
                        """)
            
            # ===== äº‹ä»¶ç»‘å®š =====
            
            # å®šä¹‰ç»Ÿä¸€çš„åˆ†æå‡½æ•°
            def analyze_with_source(source_type, camera_img, upload_img, question):
                """
                æ ¹æ®å›¾ç‰‡æ¥æºè¿›è¡Œåˆ†æ
                
                Args:
                    source_type: å›¾ç‰‡æ¥æºç±»å‹ï¼ˆè‡ªåŠ¨åˆ¤æ–­ï¼‰
                    camera_img: æ‘„åƒå¤´å›¾ç‰‡
                    upload_img: ä¸Šä¼ çš„å›¾ç‰‡
                    question: ç”¨æˆ·é—®é¢˜
                """
                # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªå›¾ç‰‡æº
                if camera_img is not None:
                    return analyze_image(camera_img, question)
                elif upload_img is not None:
                    return analyze_image(upload_img, question)
                else:
                    return "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨æ‘„åƒå¤´æ‹ç…§"
            
            # åˆ†ææŒ‰é’®ç‚¹å‡»äº‹ä»¶
            analyze_btn.click(
                fn=lambda c, u, q: analyze_with_source("both", c, u, q),
                inputs=[camera_input, upload_input, question_input],
                outputs=[result_output]
            )
            
            # æ‘„åƒå¤´æ‹ç…§åè‡ªåŠ¨åˆ†æ
            camera_input.change(
                fn=lambda img, q: analyze_image(img, q) if img is not None else "",
                inputs=[camera_input, question_input],
                outputs=[result_output]
            )
            
            # ä¸Šä¼ å›¾ç‰‡åè‡ªåŠ¨åˆ†æ
            upload_input.change(
                fn=lambda img, q: analyze_image(img, q) if img is not None else "",
                inputs=[upload_input, question_input],
                outputs=[result_output]
            )
        
        # ==================== Tab 3: è¯­éŸ³è¯†åˆ« ====================
        with gr.Tab("ğŸ¤ è¯­éŸ³è¯†åˆ«"):
            with gr.Row():
                # å·¦ä¾§ï¼šéŸ³é¢‘è¾“å…¥
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ™ï¸ éŸ³é¢‘æ¥æº
                    æ”¯æŒä¸¤ç§æ–¹å¼è¾“å…¥éŸ³é¢‘:
                    """)
                    
                    with gr.Tabs():
                        # éº¦å…‹é£å½•éŸ³
                        with gr.Tab("ğŸ™ï¸ éº¦å…‹é£"):
                            microphone_input = gr.Audio(
                                label="éº¦å…‹é£å½•éŸ³",
                                sources=["microphone"],  # åªå…è®¸éº¦å…‹é£
                                type="filepath"
                            )
                        
                        # ä¸Šä¼ éŸ³é¢‘
                        with gr.Tab("ğŸ“ ä¸Šä¼ éŸ³é¢‘"):
                            audio_upload_input = gr.Audio(
                                label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                                sources=["upload"],  # åªå…è®¸ä¸Šä¼ 
                                type="filepath"
                            )
                    
                    gr.Markdown("""
                    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
                    1. **éº¦å…‹é£æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ™ï¸éº¦å…‹é£"æ ‡ç­¾
                       - ç‚¹å‡»å½•éŸ³æŒ‰é’®å¼€å§‹å½•éŸ³
                       - å†æ¬¡ç‚¹å‡»åœæ­¢å½•éŸ³
                       - è‡ªåŠ¨å¼€å§‹è¯†åˆ«
                    
                    2. **ä¸Šä¼ æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ“ä¸Šä¼ éŸ³é¢‘"æ ‡ç­¾
                       - æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
                       - æ”¯æŒ MP3, WAV, M4A, FLAC, OGG ç­‰æ ¼å¼
                    
                    3. **è¯­è¨€è®¾ç½®**:
                       - åœ¨å³ä¾§é€‰æ‹©éŸ³é¢‘è¯­è¨€
                       - "è‡ªåŠ¨æ£€æµ‹"é€‚åˆå¤§å¤šæ•°åœºæ™¯
                    
                    ### âš™ï¸ å½“å‰æ¨¡å‹
                    """)
                    
                    gr.Markdown(f"`{settings.SPEECH_MODEL}`")
                    
                    # æ”¯æŒçš„æ ¼å¼è¯´æ˜
                    with gr.Accordion("ğŸ“– æ”¯æŒçš„æ ¼å¼", open=False):
                        gr.Markdown("""
                        **éŸ³é¢‘æ ¼å¼**:
                        - MP3 (.mp3)
                        - WAV (.wav)
                        - M4A (.m4a)
                        - FLAC (.flac)
                        - OGG (.ogg)
                        - WebM (.webm)
                        
                        **å»ºè®®**:
                        - æ–‡ä»¶å¤§å°: < 25MB
                        - éŸ³é¢‘æ—¶é•¿: < 30åˆ†é’Ÿ
                        - æ¸…æ™°çš„è¯­éŸ³æ•ˆæœæ›´å¥½
                        """)
                
                # å³ä¾§ï¼šè¯†åˆ«ç»“æœ
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¯ è¯†åˆ«ç»“æœ")
                    
                    # è¯­è¨€é€‰æ‹©
                    language_selector = gr.Radio(
                        choices=["è‡ªåŠ¨æ£€æµ‹", "ä¸­æ–‡", "è‹±æ–‡", "æ—¥è¯­", "ç²¤è¯­"],
                        value="è‡ªåŠ¨æ£€æµ‹",
                        label="è¯­è¨€é€‰æ‹©",
                        info="é€‰æ‹©éŸ³é¢‘çš„è¯­è¨€ï¼Œæ¨èä½¿ç”¨è‡ªåŠ¨æ£€æµ‹"
                    )
                    
                    # è¯†åˆ«æŒ‰é’®
                    transcribe_btn = gr.Button("ğŸ¤ å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
                    
                    # ç»“æœæ˜¾ç¤º
                    transcribe_output = gr.Textbox(
                        label="è¯†åˆ«æ–‡æœ¬",
                        lines=15,
                        placeholder="è¯†åˆ«ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                        show_copy_button=True  # æ˜¾ç¤ºå¤åˆ¶æŒ‰é’®
                    )
                    
                    # ç¤ºä¾‹åœºæ™¯
                    with gr.Accordion("ğŸ“– ä½¿ç”¨åœºæ™¯", open=False):
                        gr.Markdown("""
                        **å¸¸è§åº”ç”¨**:
                        - ğŸ“ ä¼šè®®è®°å½•è½¬æ–‡å­—
                        - ğŸ“ è¯¾å ‚ç¬”è®°æ•´ç†
                        - ğŸ“± è¯­éŸ³æ¶ˆæ¯è½¬æ–‡å­—
                        - ğŸ¬ è§†é¢‘å­—å¹•ç”Ÿæˆ
                        - ğŸ“ ç”µè¯å½•éŸ³è½¬å†™
                        
                        **å¤šè¯­è¨€æ”¯æŒ**:
                        - ğŸ‡¨ğŸ‡³ ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰
                        - ğŸ‡ºğŸ‡¸ è‹±æ–‡
                        - ğŸ‡¯ğŸ‡µ æ—¥è¯­
                        - ğŸ‡­ğŸ‡° ç²¤è¯­
                        - å…¶ä»–è¯­è¨€è¯·é€‰æ‹©"è‡ªåŠ¨æ£€æµ‹"
                        
                        **æç¤º**:
                        - èƒŒæ™¯å™ªéŸ³è¶Šå°‘ï¼Œè¯†åˆ«è¶Šå‡†ç¡®
                        - è¯´è¯æ¸…æ™°æ¯”é€Ÿåº¦å¿«æ›´é‡è¦
                        - é•¿éŸ³é¢‘ä¼šè‡ªåŠ¨åˆ†æ®µå¤„ç†
                        """)
            
            # ===== äº‹ä»¶ç»‘å®š =====
            
            # å®šä¹‰ç»Ÿä¸€çš„è¯†åˆ«å‡½æ•°
            def transcribe_with_source(microphone_audio, upload_audio, language):
                """
                æ ¹æ®éŸ³é¢‘æ¥æºè¿›è¡Œè¯†åˆ«
                
                Args:
                    microphone_audio: éº¦å…‹é£å½•éŸ³
                    upload_audio: ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
                    language: è¯­è¨€é€‰æ‹©
                """
                # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªéŸ³é¢‘æº
                if microphone_audio is not None:
                    return transcribe_audio(microphone_audio, language)
                elif upload_audio is not None:
                    return transcribe_audio(upload_audio, language)
                else:
                    return "âš ï¸ è¯·å…ˆå½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
            
            # è¯†åˆ«æŒ‰é’®ç‚¹å‡»äº‹ä»¶
            transcribe_btn.click(
                fn=transcribe_with_source,
                inputs=[microphone_input, audio_upload_input, language_selector],
                outputs=[transcribe_output]
            )
            
            # éº¦å…‹é£å½•éŸ³å®Œæˆåè‡ªåŠ¨è¯†åˆ«
            microphone_input.stop_recording(
                fn=lambda audio, lang: transcribe_audio(audio, lang) if audio is not None else "",
                inputs=[microphone_input, language_selector],
                outputs=[transcribe_output]
            )
            
            # ä¸Šä¼ éŸ³é¢‘åè‡ªåŠ¨è¯†åˆ«
            audio_upload_input.change(
                fn=lambda audio, lang: transcribe_audio(audio, lang) if audio is not None else "",
                inputs=[audio_upload_input, language_selector],
                outputs=[transcribe_output]
            )
        
        # ==================== åº•éƒ¨ä¿¡æ¯ ====================
        gr.Markdown("""
        ---
        ### ğŸ“š ç›¸å…³èµ„æº
        - [ç¡…åŸºæµåŠ¨å®˜ç½‘](https://siliconflow.cn)
        - [APIæ–‡æ¡£](https://docs.siliconflow.cn)
        - [è·å–API Key](https://cloud.siliconflow.cn/account/ak)
        
        ### ğŸ”§ æŠ€æœ¯æ ˆ
        - **æ–‡æœ¬å¯¹è¯**: OpenAIå…¼å®¹API (Chat Completions)
        - **è¯­éŸ³åˆæˆ**: TTS API (Text-to-Speech)
        - **è¯­éŸ³è¯†åˆ«**: ASR API (Automatic Speech Recognition)
        - **å›¾åƒè¯†åˆ«**: Vision Language Model (VLM)
        - **æ¡†æ¶**: Gradio 4.0+ Â· Python 3.9+
        """)
    
    return demo


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ç¨‹åºå…¥å£"""
    logger.info("=" * 60)
    logger.info("å¯åŠ¨ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo")
    logger.info("=" * 60)
    
    try:
        # ===== 1. éªŒè¯é…ç½® =====
        settings.validate()
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        
        # ===== 2. åˆ›å»ºè¾“å‡ºç›®å½• =====
        ensure_output_dirs()
        logger.info(f"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º:")
        logger.info(f"   - éŸ³é¢‘: {settings.AUDIO_OUTPUT_DIR}")
        logger.info(f"   - å›¾ç‰‡: {settings.IMAGE_OUTPUT_DIR}")
        
        # ===== 3. æ˜¾ç¤ºé…ç½®ä¿¡æ¯ =====
        logger.info(f"ğŸ“ æ–‡æœ¬æ¨¡å‹: {settings.TEXT_MODEL}")
        logger.info(f"ğŸ”Š è¯­éŸ³åˆæˆ: {settings.TTS_MODEL}")
        logger.info(f"ğŸ¤ è¯­éŸ³è¯†åˆ«: {settings.SPEECH_MODEL}")
        logger.info(f"ğŸ–¼ï¸ å›¾åƒè¯†åˆ«: {settings.VLM_MODEL}")
        logger.info(f"ğŸ”— APIåœ°å€: {settings.SILICONFLOW_BASE_URL}")
        
    except ValueError as e:
        logger.error(f"âŒ é…ç½®é”™è¯¯: {e}")
        logger.info("ğŸ’¡ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®:")
        logger.info("   1. å¤åˆ¶ env_template.txt ä¸º .env")
        logger.info("   2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ API Key")
        logger.info("   3. API Keyè·å–: https://cloud.siliconflow.cn/account/ak")
        return
    
    # ===== 4. åˆ›å»ºå¹¶å¯åŠ¨Demo =====
    demo = create_demo()
    
    logger.info("ğŸš€ å¯åŠ¨ Gradio æœåŠ¡...")
    logger.info("=" * 60)
    
    demo.launch(
        server_name="127.0.0.1",
        server_port=7862,
        share=False,
        show_error=True,
        inbrowser=True
    )


if __name__ == "__main__":
    main()

