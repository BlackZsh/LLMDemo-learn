"""
ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo - å®Œæ•´ç‰ˆ
é›†æˆæ–‡æœ¬å¯¹è¯ã€è¯­éŸ³åˆæˆã€å›¾åƒè¯†åˆ«åŠŸèƒ½
"""
import gradio as gr
import os
import time
from pathlib import Path
from loguru import logger
import sys

# å¯¼å…¥APIæ¨¡å—
from api.text_api import text_api
from api.tts_api import tts_api
from api.vision_api import vision_api
from config.settings import settings

# ==================== é…ç½®æ—¥å¿— ====================
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level=settings.LOG_LEVEL
)


# ==================== å·¥å…·å‡½æ•° ====================

def ensure_output_dirs():
    """
    ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    åˆ›å»ºéŸ³é¢‘å’Œå›¾ç‰‡çš„ä¿å­˜ç›®å½•
    """
    Path(settings.AUDIO_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    Path(settings.IMAGE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)


def convert_history_to_tuples(messages):
    """
    å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„æ ¼å¼
    
    Args:
        messages: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
        
    Returns:
        [("user_msg", "assistant_msg"), ...]
    
    è¯´æ˜:
        è¿™ä¸ªè½¬æ¢æ˜¯ä¸ºäº†å…¼å®¹text_apiçš„å†å²è®°å½•æ ¼å¼
    """
    history = []
    i = 0
    while i < len(messages):
        # æ¯æ¬¡å¤„ç†ä¸€å¯¹user-assistantæ¶ˆæ¯
        if i + 1 < len(messages) and messages[i]["role"] == "user" and messages[i+1]["role"] == "assistant":
            history.append((messages[i]["content"], messages[i+1]["content"]))
            i += 2
        else:
            i += 1
    return history


# ==================== æ–‡æœ¬å¯¹è¯åŠŸèƒ½ ====================

def chat_stream_response(message, history):
    """
    å¤„ç†æµå¼èŠå¤©å“åº”ï¼ˆçº¯æ–‡æœ¬å¯¹è¯ï¼Œå‚è€ƒ demo_text.py çš„æ¸…æ™°é€»è¾‘ï¼‰
    
    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        history: å†å²å¯¹è¯è®°å½•ï¼ˆOpenAIæ ¼å¼ï¼‰
        
    Yields:
        æ›´æ–°çš„å†å²è®°å½•
        
    åŠŸèƒ½æµç¨‹:
        1. ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å² â†’ ç”¨æˆ·ç«‹å³çœ‹åˆ°è‡ªå·±çš„è¾“å…¥
        2. æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯ â†’ å‡†å¤‡æ¥æ”¶æµå¼è¾“å‡º
        3. æµå¼è·å–AIå›å¤ â†’ é€å­—æ˜¾ç¤ºï¼Œä½“éªŒæµç•…
    """
    try:
        # éªŒè¯é…ç½®
        settings.validate()
        
        # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        history.append({"role": "user", "content": message})
        yield history
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
        history.append({"role": "assistant", "content": ""})
        yield history
        
        # è½¬æ¢å†å²æ ¼å¼ç”¨äºAPIè°ƒç”¨
        chat_history = convert_history_to_tuples(history[:-2])  # ä¸åŒ…æ‹¬å½“å‰æ¶ˆæ¯
        
        # è°ƒç”¨æµå¼API
        logger.info(f"ç”¨æˆ·è¾“å…¥(æµå¼): {message}")
        full_response = ""
        for chunk in text_api.chat_stream(message=message, history=chat_history):
            full_response += chunk
            history[-1]["content"] = full_response
            yield history
        
        logger.info(f"æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)}")
        
    except ValueError as e:
        error_msg = f"âš ï¸ é…ç½®é”™è¯¯: {str(e)}\n\nè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶é…ç½® SILICONFLOW_API_KEY"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history
    except Exception as e:
        error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        if history and history[-1]["role"] == "assistant":
            history[-1]["content"] = error_msg
        yield history


def synthesize_speech(text):
    """
    è¯­éŸ³åˆæˆåŠŸèƒ½ï¼ˆç‹¬ç«‹å‡½æ•°ï¼Œä½œä¸ºå¯é€‰çš„åå¤„ç†æ­¥éª¤ï¼‰
    
    Args:
        text: è¦åˆæˆè¯­éŸ³çš„æ–‡æœ¬
        
    Returns:
        str: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
    """
    try:
        if not text or not text.strip():
            return None
            
        logger.info("å¼€å§‹è¯­éŸ³åˆæˆ...")
        
        # ç”Ÿæˆå”¯ä¸€çš„éŸ³é¢‘æ–‡ä»¶å
        timestamp = int(time.time())
        audio_filename = f"tts_{timestamp}.wav"
        audio_path = os.path.join(settings.AUDIO_OUTPUT_DIR, audio_filename)
        
        # è°ƒç”¨TTS API
        tts_api.synthesize(text=text, save_path=audio_path)
        
        logger.info(f"âœ… è¯­éŸ³åˆæˆæˆåŠŸ: {audio_path}")
        return audio_path
        
    except Exception as e:
        logger.warning(f"âš ï¸ è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
        return None


# ==================== å›¾åƒè¯†åˆ«åŠŸèƒ½ ====================

def analyze_image(image, question):
    """
    åˆ†æå›¾ç‰‡å†…å®¹
    
    Args:
        image: å›¾ç‰‡æ–‡ä»¶ï¼ˆæ¥è‡ªæ‘„åƒå¤´æˆ–ä¸Šä¼ ï¼‰
                - None: æ²¡æœ‰å›¾ç‰‡
                - str: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                - numpy.ndarray: å›¾ç‰‡æ•°ç»„ï¼ˆæ‘„åƒå¤´æ‹æ‘„ï¼‰
        question: ç”¨æˆ·å¯¹å›¾ç‰‡çš„æé—®
                 - å¦‚æœä¸ºç©ºï¼Œé»˜è®¤æè¿°å›¾ç‰‡å†…å®¹
                 - å¦‚æœæœ‰å†…å®¹ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜
        
    Returns:
        str: å›¾ç‰‡åˆ†æç»“æœ
        
    åŠŸèƒ½è¯´æ˜:
        1. æ”¯æŒæ‘„åƒå¤´æ‹ç…§
        2. æ”¯æŒä¸Šä¼ æœ¬åœ°å›¾ç‰‡
        3. å¯ä»¥æè¿°å›¾ç‰‡å†…å®¹
        4. å¯ä»¥å›ç­”å…³äºå›¾ç‰‡çš„é—®é¢˜
    """
    try:
        # ===== æ­¥éª¤1: æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ =====
        if image is None:
            return "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨æ‘„åƒå¤´æ‹ç…§"
        
        # ===== æ­¥éª¤2: å¤„ç†ä¸åŒç±»å‹çš„å›¾ç‰‡è¾“å…¥ =====
        import numpy as np
        from PIL import Image
        
        if isinstance(image, np.ndarray):
            # å¦‚æœæ˜¯numpyæ•°ç»„ï¼ˆæ¥è‡ªæ‘„åƒå¤´ï¼‰ï¼Œå…ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            logger.info("å¤„ç†æ‘„åƒå¤´å›¾ç‰‡")
            
            # è½¬æ¢ä¸ºPIL Image
            pil_image = Image.fromarray(image)
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            timestamp = int(time.time())
            temp_image_path = os.path.join(settings.IMAGE_OUTPUT_DIR, f"camera_{timestamp}.jpg")
            pil_image.save(temp_image_path)
            
            image_source = temp_image_path
            logger.info(f"æ‘„åƒå¤´å›¾ç‰‡å·²ä¿å­˜: {temp_image_path}")
            
        else:
            # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            image_source = image
            logger.info(f"å¤„ç†ä¸Šä¼ å›¾ç‰‡: {image_source}")
        
        # ===== æ­¥éª¤3: æ„å»ºæç¤ºè¯ =====
        if question and question.strip():
            # ç”¨æˆ·æœ‰å…·ä½“é—®é¢˜
            prompt = question
            logger.info(f"ç”¨æˆ·é—®é¢˜: {question}")
        else:
            # é»˜è®¤æè¿°å›¾ç‰‡
            prompt = None  # vision_apiä¼šä½¿ç”¨é»˜è®¤æç¤ºè¯
            logger.info("ä½¿ç”¨é»˜è®¤æè¿°æ¨¡å¼")
        
        # ===== æ­¥éª¤4: è°ƒç”¨Vision API =====
        logger.info("å¼€å§‹åˆ†æå›¾ç‰‡...")
        description = vision_api.describe_image(
            image_source=image_source,
            prompt=prompt,
            detail="auto"  # è‡ªåŠ¨é€‰æ‹©åˆ†æè¯¦ç»†ç¨‹åº¦
        )
        
        logger.info(f"å›¾ç‰‡åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(description)}")
        return description
        
    except Exception as e:
        error_msg = f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg


# ==================== Gradioç•Œé¢ ====================

def create_demo():
    """
    åˆ›å»ºGradioå¤šæ¨¡æ€æ¼”ç¤ºç•Œé¢
    
    ç•Œé¢ç»“æ„:
        - Tab 1: æ–‡æœ¬å¯¹è¯ï¼ˆæ”¯æŒè¯­éŸ³æ’­æŠ¥ï¼‰
        - Tab 2: å›¾åƒè¯†åˆ«ï¼ˆæ”¯æŒæ‘„åƒå¤´å’Œä¸Šä¼ ï¼‰
    """
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        max-width: 1400px !important;
        margin: auto !important;
    }
    .header {
        text-align: center;
        padding: 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .info-box {
        background-color: #f0f7ff;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 10px 0;
    }
    """
    
    with gr.Blocks(css=custom_css, theme=gr.themes.Soft(), title="ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo") as demo:
        
        # ==================== é¡µé¢æ ‡é¢˜ ====================
        gr.HTML("""
        <div class="header">
            <h1>ğŸ¤– å¤šæ¨¡æ€AIåŠ©æ‰‹ Demo</h1>
            <p>æ–‡æœ¬å¯¹è¯ Â· è¯­éŸ³åˆæˆ Â· å›¾åƒè¯†åˆ« - ä¸€ç«™å¼AIä½“éªŒ</p>
        </div>
        """)
        
        # ==================== Tab 1: æ–‡æœ¬å¯¹è¯ ====================
        with gr.Tab("ğŸ’¬ æ™ºèƒ½å¯¹è¯"):
            with gr.Row():
                # å·¦ä¾§ï¼šé…ç½®å’Œè¯´æ˜
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ“‹ åŠŸèƒ½è¯´æ˜
                    - âœ… å¤šè½®å¯¹è¯è®°å¿†
                    - âœ… æµå¼å®æ—¶è¾“å‡º
                    - ğŸ”Š è¯­éŸ³æ’­æŠ¥ï¼ˆå¯é€‰ï¼‰
                    
                    ### âš™ï¸ å½“å‰é…ç½®
                    """)
                    
                    with gr.Group():
                        gr.Markdown(f"""
                        - **æ–‡æœ¬æ¨¡å‹**: `{settings.TEXT_MODEL}`
                        - **è¯­éŸ³æ¨¡å‹**: `{settings.TTS_MODEL}`
                        - **æœ€å¤§Token**: `{settings.MAX_TOKENS}`
                        - **æ¸©åº¦**: `{settings.TEMPERATURE}`
                        """)
                    
                    gr.Markdown("""
                    ### ğŸ’¡ ç¤ºä¾‹é—®é¢˜
                    - è¯·ä»‹ç»ä¸€ä¸‹ç¡…åŸºæµåŠ¨
                    - å†™ä¸€ä¸ªPythonå¿«é€Ÿæ’åº
                    - è§£é‡Šä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹
                    - å¸®æˆ‘å†™é¦–å…³äºAIçš„è¯—
                    """)
                
                # å³ä¾§ï¼šå¯¹è¯ç•Œé¢
                with gr.Column(scale=2):
                    # èŠå¤©çª—å£ï¼ˆä½¿ç”¨messagesæ ¼å¼ï¼‰
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯çª—å£",
                        height=450,
                        type="messages",  # OpenAIæ ¼å¼
                        avatar_images=(None, "ğŸ¤–")
                    )
                    
                    # éŸ³é¢‘æ’­æ”¾å™¨
                    audio_output = gr.Audio(
                        label="è¯­éŸ³æ’­æŠ¥",
                        type="filepath",
                        autoplay=True,  # è‡ªåŠ¨æ’­æ”¾
                        visible=True
                    )
                    
                    # è¾“å…¥åŒºåŸŸ
                    with gr.Row():
                        msg = gr.Textbox(
                            label="è¾“å…¥æ¶ˆæ¯",
                            placeholder="è¯·è¾“å…¥æ¶ˆæ¯...",
                            lines=2,
                            scale=4
                        )
                    
                    # æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        enable_tts = gr.Checkbox(
                            label="ğŸ”Š è¯­éŸ³æ’­æŠ¥",
                            value=False,
                            info="å‹¾é€‰åå°†å›å¤è½¬ä¸ºè¯­éŸ³"
                        )
                        send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", scale=1)
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", scale=1)
            
            # ===== äº‹ä»¶ç»‘å®š =====
            
            # åŒ…è£…å‡½æ•°ï¼šå¤„ç†æµå¼å“åº”ï¼ˆå‚è€ƒ demo_text.py çš„æ¸…æ™°ç»“æ„ï¼‰
            def handle_stream_wrapper(message, history, enable_tts):
                """
                å¤„ç†æµå¼æäº¤çš„åŒ…è£…å‡½æ•°
                
                åŠŸèƒ½:
                    1. æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
                    2. æ¸…ç©ºè¾“å…¥æ¡†
                    3. æµå¼æ›´æ–°å¯¹è¯
                    4. ï¼ˆå¯é€‰ï¼‰ç”Ÿæˆè¯­éŸ³
                """
                if not message or not message.strip():
                    return history, "", None
                
                # å…ˆæ¸…ç©ºè¾“å…¥æ¡†
                yield history, "", None
                
                # æµå¼è·å–æ–‡æœ¬å“åº”
                final_history = None
                for updated_history in chat_stream_response(message, history):
                    final_history = updated_history
                    yield updated_history, "", None
                
                # å¦‚æœå¯ç”¨TTSï¼Œåœ¨æ–‡æœ¬å“åº”å®Œæˆåç”Ÿæˆè¯­éŸ³
                audio_path = None
                if enable_tts and final_history and final_history[-1]["role"] == "assistant":
                    response_text = final_history[-1]["content"]
                    audio_path = synthesize_speech(response_text)
                
                # æœ€ç»ˆè¾“å‡ºï¼ˆå¸¦æˆ–ä¸å¸¦éŸ³é¢‘ï¼‰
                yield final_history, "", audio_path
            
            # Enteré”®æäº¤
            msg.submit(
                fn=handle_stream_wrapper,
                inputs=[msg, chatbot, enable_tts],
                outputs=[chatbot, msg, audio_output]
            )
            
            # å‘é€æŒ‰é’®
            send_btn.click(
                fn=handle_stream_wrapper,
                inputs=[msg, chatbot, enable_tts],
                outputs=[chatbot, msg, audio_output]
            )
            
            # æ¸…ç©ºæŒ‰é’®
            clear_btn.click(
                fn=lambda: ([], "", None),
                outputs=[chatbot, msg, audio_output]
            )
        
        # ==================== Tab 2: å›¾åƒè¯†åˆ« ====================
        with gr.Tab("ğŸ–¼ï¸ å›¾åƒè¯†åˆ«"):
            with gr.Row():
                # å·¦ä¾§ï¼šå›¾ç‰‡è¾“å…¥
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ“¸ å›¾ç‰‡æ¥æº
                    æ”¯æŒä¸¤ç§æ–¹å¼è¾“å…¥å›¾ç‰‡:
                    """)
                    
                    with gr.Tabs():
                        # æ‘„åƒå¤´æ‹ç…§
                        with gr.Tab("ğŸ“· æ‘„åƒå¤´"):
                            camera_input = gr.Image(
                                label="æ‘„åƒå¤´",
                                sources=["webcam"],  # åªå…è®¸æ‘„åƒå¤´
                                type="numpy"
                            )
                        
                        # ä¸Šä¼ å›¾ç‰‡
                        with gr.Tab("ğŸ“ ä¸Šä¼ "):
                            upload_input = gr.Image(
                                label="ä¸Šä¼ å›¾ç‰‡",
                                sources=["upload"],  # åªå…è®¸ä¸Šä¼ 
                                type="filepath"
                            )
                    
                    gr.Markdown("""
                    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
                    1. **æ‘„åƒå¤´æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ“·æ‘„åƒå¤´"æ ‡ç­¾
                       - ç‚¹å‡»ç›¸æœºå›¾æ ‡æ‹ç…§
                       - ç…§ç‰‡ä¼šè‡ªåŠ¨åˆ†æ
                    
                    2. **ä¸Šä¼ æ¨¡å¼**:
                       - ç‚¹å‡»"ğŸ“ä¸Šä¼ "æ ‡ç­¾
                       - æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼ å›¾ç‰‡
                       - æ”¯æŒ JPG, PNG, WebP ç­‰æ ¼å¼
                    
                    3. **æé—®æ¨¡å¼**:
                       - åœ¨å³ä¾§è¾“å…¥å…·ä½“é—®é¢˜
                       - ç•™ç©ºåˆ™è‡ªåŠ¨æè¿°å›¾ç‰‡å†…å®¹
                    
                    ### âš™ï¸ å½“å‰æ¨¡å‹
                    """)
                    
                    gr.Markdown(f"`{settings.VLM_MODEL}`")
                
                # å³ä¾§ï¼šè¯†åˆ«ç»“æœ
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¯ è¯†åˆ«ç»“æœ")
                    
                    # é—®é¢˜è¾“å…¥æ¡†
                    question_input = gr.Textbox(
                        label="å‘AIæé—®ï¼ˆå¯é€‰ï¼‰",
                        placeholder="ä¾‹å¦‚: å›¾ç‰‡ä¸­æœ‰å‡ ä¸ªäºº? è¿™æ˜¯ä»€ä¹ˆåœ°æ–¹? å›¾ç‰‡çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆ?",
                        lines=2
                    )
                    
                    # åˆ†ææŒ‰é’®
                    analyze_btn = gr.Button("ğŸ” åˆ†æå›¾ç‰‡", variant="primary", size="lg")
                    
                    # ç»“æœæ˜¾ç¤º
                    result_output = gr.Textbox(
                        label="åˆ†æç»“æœ",
                        lines=15,
                        placeholder="åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                        show_copy_button=True  # æ˜¾ç¤ºå¤åˆ¶æŒ‰é’®
                    )
                    
                    # ç¤ºä¾‹é—®é¢˜
                    with gr.Accordion("ğŸ“– ç¤ºä¾‹é—®é¢˜", open=False):
                        gr.Markdown("""
                        **æè¿°ç±»**:
                        - è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡
                        - å›¾ç‰‡çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ
                        - è¿™å¼ å›¾ç‰‡ç»™ä½ ä»€ä¹ˆæ„Ÿè§‰ï¼Ÿ
                        
                        **è¯†åˆ«ç±»**:
                        - å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆç‰©ä½“ï¼Ÿ
                        - èƒ½è®¤å‡ºè¿™æ˜¯ä»€ä¹ˆåœ°æ–¹å—ï¼Ÿ
                        - å›¾ç‰‡ä¸­æœ‰å‡ ä¸ªäººï¼Ÿ
                        
                        **åˆ†æç±»**:
                        - å›¾ç‰‡çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
                        - è¿™å¼ å›¾ç‰‡å¯èƒ½åœ¨è¡¨è¾¾ä»€ä¹ˆï¼Ÿ
                        - å›¾ç‰‡çš„è‰²è°ƒå’Œæ°›å›´å¦‚ä½•ï¼Ÿ
                        """)
            
            # ===== äº‹ä»¶ç»‘å®š =====
            
            # å®šä¹‰ç»Ÿä¸€çš„åˆ†æå‡½æ•°
            def analyze_with_source(source_type, camera_img, upload_img, question):
                """
                æ ¹æ®å›¾ç‰‡æ¥æºè¿›è¡Œåˆ†æ
                
                Args:
                    source_type: å›¾ç‰‡æ¥æºç±»å‹ï¼ˆè‡ªåŠ¨åˆ¤æ–­ï¼‰
                    camera_img: æ‘„åƒå¤´å›¾ç‰‡
                    upload_img: ä¸Šä¼ çš„å›¾ç‰‡
                    question: ç”¨æˆ·é—®é¢˜
                """
                # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªå›¾ç‰‡æº
                if camera_img is not None:
                    return analyze_image(camera_img, question)
                elif upload_img is not None:
                    return analyze_image(upload_img, question)
                else:
                    return "âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨æ‘„åƒå¤´æ‹ç…§"
            
            # åˆ†ææŒ‰é’®ç‚¹å‡»äº‹ä»¶
            analyze_btn.click(
                fn=lambda c, u, q: analyze_with_source("both", c, u, q),
                inputs=[camera_input, upload_input, question_input],
                outputs=[result_output]
            )
            
            # æ‘„åƒå¤´æ‹ç…§åè‡ªåŠ¨åˆ†æ
            camera_input.change(
                fn=lambda img, q: analyze_image(img, q) if img is not None else "",
                inputs=[camera_input, question_input],
                outputs=[result_output]
            )
            
            # ä¸Šä¼ å›¾ç‰‡åè‡ªåŠ¨åˆ†æ
            upload_input.change(
                fn=lambda img, q: analyze_image(img, q) if img is not None else "",
                inputs=[upload_input, question_input],
                outputs=[result_output]
            )
        
        # ==================== åº•éƒ¨ä¿¡æ¯ ====================
        gr.Markdown("""
        ---
        ### ğŸ“š ç›¸å…³èµ„æº
        - [ç¡…åŸºæµåŠ¨å®˜ç½‘](https://siliconflow.cn)
        - [APIæ–‡æ¡£](https://docs.siliconflow.cn)
        - [è·å–API Key](https://cloud.siliconflow.cn/account/ak)
        
        ### ğŸ”§ æŠ€æœ¯æ ˆ
        - **æ–‡æœ¬**: OpenAIå…¼å®¹API (Chat Completions)
        - **è¯­éŸ³**: TTS API (Text-to-Speech)
        - **è§†è§‰**: Vision Language Model (VLM)
        - **æ¡†æ¶**: Gradio 4.0+ Â· Python 3.9+
        """)
    
    return demo


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ç¨‹åºå…¥å£"""
    logger.info("=" * 60)
    logger.info("å¯åŠ¨ç¡…åŸºæµåŠ¨å¤šæ¨¡æ€AIåŠ©æ‰‹Demo")
    logger.info("=" * 60)
    
    try:
        # ===== 1. éªŒè¯é…ç½® =====
        settings.validate()
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        
        # ===== 2. åˆ›å»ºè¾“å‡ºç›®å½• =====
        ensure_output_dirs()
        logger.info(f"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º:")
        logger.info(f"   - éŸ³é¢‘: {settings.AUDIO_OUTPUT_DIR}")
        logger.info(f"   - å›¾ç‰‡: {settings.IMAGE_OUTPUT_DIR}")
        
        # ===== 3. æ˜¾ç¤ºé…ç½®ä¿¡æ¯ =====
        logger.info(f"ğŸ“ æ–‡æœ¬æ¨¡å‹: {settings.TEXT_MODEL}")
        logger.info(f"ğŸ”Š è¯­éŸ³æ¨¡å‹: {settings.TTS_MODEL}")
        logger.info(f"ğŸ–¼ï¸ å›¾åƒæ¨¡å‹: {settings.VLM_MODEL}")
        logger.info(f"ğŸ”— APIåœ°å€: {settings.SILICONFLOW_BASE_URL}")
        
    except ValueError as e:
        logger.error(f"âŒ é…ç½®é”™è¯¯: {e}")
        logger.info("ğŸ’¡ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®:")
        logger.info("   1. å¤åˆ¶ env_template.txt ä¸º .env")
        logger.info("   2. ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ API Key")
        logger.info("   3. API Keyè·å–: https://cloud.siliconflow.cn/account/ak")
        return
    
    # ===== 4. åˆ›å»ºå¹¶å¯åŠ¨Demo =====
    demo = create_demo()
    
    logger.info("ğŸš€ å¯åŠ¨ Gradio æœåŠ¡...")
    logger.info("=" * 60)
    
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7862,        # ç«¯å£å·
        share=True,              # åˆ›å»ºå…¬ç½‘é“¾æ¥ï¼ˆå¯é€‰ï¼‰
        show_error=True          # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    )


if __name__ == "__main__":
    main()

